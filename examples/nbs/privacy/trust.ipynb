{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parallel_db(tensor, remove_index):\n",
    "    \"remove an entry at the associated index\"\n",
    "    return torch.cat( (tensor[0:remove_index], tensor[remove_index+1:]) )\n",
    "\n",
    "def create_dbs_parallel(database):\n",
    "    \"remove an entry (user) from muliple different variations of queries \"\n",
    "    pdbs = [get_parallel_db(database, i) for i in range(len(database)) ]\n",
    "    return pdbs\n",
    "\n",
    "num_entries = 10\n",
    "db   = torch.rand(num_entries) > 0.5\n",
    "db   = db.type(torch.IntTensor)\n",
    "pdbs = create_dbs_parallel(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity\n",
    "- determine sensitivity of information that changes; how queries leak information \n",
    "- L1 Sensitivity: maximum amount query changes when removing an individual from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query database and measure the privacy of the query to determine if result is leaking information \n",
    "# does the output change when removing an (entry=user) from the database\n",
    "def query_statistic(database, fn_metric):\n",
    "    return fn_metric(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori_min, apriori_max = (min(db), max(db))\n",
    "sensitivity = 0\n",
    "db_full_stat = query_statistic(db, torch.sum)\n",
    "for pdb in pdbs:\n",
    "    pdb_result = query_statistic(pdb, torch.sum)\n",
    "    pdb_dist   = torch.abs(pdb_result - db_full_stat)\n",
    "    if pdb_dist > sensitivity:\n",
    "        sensitivity = pdb_dist\n",
    "sensitivity    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori_min, apriori_max = (min(db), max(db))\n",
    "db_full_stat   = query_statistic(db, torch.sum)\n",
    "sensity_fn_l1  = np.max\n",
    "sensitvity_val = sensity_fn_l1([torch.abs(query_statistic(pdb, torch.sum) - db_full_stat) for pdb in pdbs])\n",
    "sensitvity_val == apriori_max, sensitvity_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning.core.v37] *",
   "language": "python",
   "name": "conda-env-deeplearning.core.v37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
